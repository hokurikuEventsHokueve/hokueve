import os
import requests
from bs4 import BeautifulSoup
from datetime import datetime
from supabase import create_client, Client

# Supabaseæ¥ç¶šè¨­å®š
url = os.environ.get("SUPABASE_URL")
key = os.environ.get("SUPABASE_ANON_KEY")
supabase: Client = create_client(url, key)

# æ¤œç´¢ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ï¼ˆé‡‘æ²¢å¸‚ï¼‰
SEARCH_KEYWORD = "é‡‘æ²¢å¸‚"

# e+æ¤œç´¢URL
BASE_URL = "https://eplus.jp/sf/search"
params = {"keyword": SEARCH_KEYWORD}

def scrape_eplus():
    print("ğŸ” e+ ã‹ã‚‰ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ä¸­...")
    res = requests.get(BASE_URL, params=params)
    res.raise_for_status()
    soup = BeautifulSoup(res.text, "html.parser")

    events = []

    cards = soup.select("a.ticket-item")

    for c in cards:
        title_elem = c.select_one(".ticket-item__title")
        year_elem = c.select_one(".ticket-item__yyyy")
        date_elem = c.select_one(".ticket-item__mmdd")
        venue_elem = c.select_one(".ticket-item__venue")
        link = c.get("href")

        title = title_elem.get_text(strip=True) if title_elem else "ï¼ˆã‚¿ã‚¤ãƒˆãƒ«ä¸æ˜ï¼‰"
        year = year_elem.get_text(strip=True) if year_elem else ""
        mmdd = date_elem.get_text(strip=True) if date_elem else ""
        venue = venue_elem.get_text(strip=True) if venue_elem else ""
        event_url = f"https://eplus.jp{link}" if link and link.startswith("/") else link

        # æ—¥ä»˜ã‚’æ•´å½¢
        try:
            date_str = f"{year}.{mmdd}".replace("/", ".")
            date = datetime.strptime(date_str, "%Y.%m.%d").date()
        except Exception:
            date = None

        events.append({
            "title": title,
            "date": date,
            "url": event_url,
            "image_url": None,
            "source": "eplus",
            "created_at": datetime.utcnow().isoformat(),
            "updated_at": datetime.utcnow().isoformat(),
        })

    print(f"âœ… {len(events)} ä»¶ã®ã‚¤ãƒ™ãƒ³ãƒˆã‚’å–å¾—ã—ã¾ã—ãŸ")
    return events

def save_to_supabase(events):
    if not events:
        print("âš ï¸ ç™»éŒ²ã™ã‚‹ã‚¤ãƒ™ãƒ³ãƒˆãŒã‚ã‚Šã¾ã›ã‚“ã€‚")
        return
    try:
        supabase.table("events").insert(events).execute()
        print(f"ğŸ’¾ Supabaseã« {len(events)} ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’ä¿å­˜ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ Supabaseã¸ã®ä¿å­˜ä¸­ã«ã‚¨ãƒ©ãƒ¼: {e}")

if __name__ == "__main__":
    events = scrape_eplus()
    save_to_supabase(events)
